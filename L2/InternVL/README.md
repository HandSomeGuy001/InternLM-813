# InternVL(å†·ç¬‘è¯å¤§å¸ˆ)éƒ¨ç½²å¾®è°ƒå®è·µ
### å¤ç°æµç¨‹
å‡†å¤‡ç¯å¢ƒï¼ˆç•¥ï¼‰  
å‡†å¤‡æ¨¡å‹/æ•°æ®é›†  
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# ln -s /root/share/new_models/datasets/CLoT_cn_2000/ ./
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# ln -s /root/share/new_models/OpenGVLab/InternVL2-2B ./
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# ls
CLoT_cn_2000  InternVL2-2B  README.md
```
å‡†å¤‡æµ‹è¯•å›¾ç‰‡
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# cp CLoT_cn_2000/ex_images/007aPnLRgy1h9bhf3l6i9j30ci0eldh5.jpg ./test.jpg
```
![æµ‹è¯•å›¾ç‰‡](./test.jpg)
æµ‹è¯•å›¾ç‰‡çš„æ•°æ®ä¿¡æ¯ğŸ‘‡
```json
{
"image": "ex_images/007aPnLRgy1h9bhf3l6i9j30ci0eldh5.jpg",
"conversations": [
    {
    "from": "human",
    "value": "<image>\nè¯·ä½ æ ¹æ®è¿™å¼ å›¾ç‰‡ï¼Œè®²ä¸€ä¸ªè„‘æ´å¤§å¼€çš„æ¢—"
    },
    {
    "from": "gpt",
    "value": "çŒœçŒœå“ªä¸ªå¤¹çš„æ˜¯ç‹—å±"
    }
]
}
```
æ ¹æ®[éƒ¨ç½²è„šæœ¬](./test_lmdeploy.py)ï¼Œè¿›è¡Œå¾®è°ƒå‰æµ‹è¯•  
æµ‹è¯•ç»“æœ(æ— flash attentionç‰ˆ)ğŸ‘‡
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_lmdeploy.py 
è¿™å¼ å›¾ç‰‡é‡Œçš„æç¬‘ç‚¹åœ¨äºï¼Œæœ‰äººæŠŠçƒ­ç‹—é€’ç»™ä¸€ä¸ªååœ¨åœ°ä¸Šã€é¢æ— è¡¨æƒ…çš„ç”·å­ï¼Œè€Œç”·å­çœ‹èµ·æ¥å®Œå…¨ä¸çŸ¥é“å¯¹æ–¹åœ¨åšä»€ä¹ˆï¼Œç”šè‡³å¯èƒ½åœ¨ç¬‘ã€‚è¿™ä¸ªåœºæ™¯å®é™…ä¸Šæ˜¯ä¸€ä¸ªâ€œæ— è¡¨æƒ…æ´¾å¯¹â€çš„æ¢—ï¼Œé€šå¸¸ç”¨äºå½¢å®¹åœ¨æ´¾å¯¹æˆ–èšä¼šä¸­ï¼ŒæŸä¸ªäººå¯¹çœ¼å‰å‘ç”Ÿçš„äº‹æƒ…æ— åŠ¨äºè¡·æˆ–æ¼ ä¸å…³å¿ƒï¼Œç”šè‡³å¯èƒ½åœ¨ç¬‘ã€‚

è¿™ä¸ªæ¢—çš„æ¥æºå¯ä»¥è¿½æº¯åˆ°ä¸€ç§â€œæ— è¡¨æƒ…æ´¾å¯¹â€çš„æµè¡Œæ–‡åŒ–ï¼Œå³äººä»¬åœ¨æ´¾å¯¹æˆ–èšä¼šä¸­ï¼Œå½“æœ‰äººå‘ä»–ä»¬å±•ç¤ºä¸€äº›æç¬‘æˆ–æ— æ„ä¹‰çš„ä¸œè¥¿æ—¶ï¼Œä»–ä»¬å¯èƒ½ä¼šæ„Ÿåˆ°å›°æƒ‘æˆ–æ— å¥ˆï¼Œç”šè‡³å¯èƒ½åœ¨ç¬‘ã€‚è¿™ä¸ªæ¢—è¢«å¹¿æ³›ç”¨äºå„ç§å¹½é»˜åœºæ™¯ä¸­ï¼Œç”¨æ¥è¡¨è¾¾ä¸€ç§â€œçœ‹å¼€â€ã€â€œæ— æ‰€è°“â€çš„æ€åº¦ã€‚

è¿™ä¸ªæ¢—ä¹‹æ‰€ä»¥æœ‰è¶£ï¼Œæ˜¯å› ä¸ºå®ƒå±•ç¤ºäº†äººä»¬é¢å¯¹çªå‘çŠ¶å†µæ—¶çš„ååº”ï¼Œçªæ˜¾äº†åœ¨é¢å¯¹æŸäº›æç¬‘æˆ–æ— æ„ä¹‰çš„äº‹æƒ…æ—¶ï¼Œäººä»¬å¾€å¾€ä¼šè¡¨ç°å‡ºä¸€ç§â€œæ— è¡¨æƒ…â€çš„æ€åº¦ï¼Œä»è€Œå¼•å‘ä¸€ç§å¹½é»˜æ•ˆæœã€‚
```
å¸¦flash attentionç‰ˆğŸ‘‡
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_lmdeploy.py 
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                     
è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†ä¸€ä¸ªæç¬‘çš„æƒ…æ™¯ï¼šä¸€ä¸ªäººæ‰‹é‡Œæ‹¿ç€ä¸¤ä¸ªçƒ­ç‹—ï¼Œè„¸ä¸Šéœ²å‡ºå¤¸å¼ çš„ç¬‘å®¹ï¼Œè€Œä¸€åªé»‘è‰²çš„ç‹—ç‹—æ­£ç«™åœ¨ä»–çš„èº«åï¼Œçœ¼ç¥ç›´å‹¾å‹¾åœ°ç›¯ç€ä»–çš„è„¸ã€‚è¿™ä¸ªåœºæ™¯è®©äººä¸ç¦è”æƒ³åˆ°ä¸€ä¸ªç»å…¸çš„â€œç‹—ç‹—åƒäººâ€çš„æ¢—ï¼Œå³ç‹—ç‹—è¢«äººç±»é£Ÿç‰©å¸å¼•ï¼Œç”šè‡³æ¥è¿‘äººç±»ï¼Œè€Œäººç±»åˆ™è¡¨ç°å‡ºä¸€ç§æ»‘ç¨½çš„ã€åƒæƒŠçš„è¡¨æƒ…ã€‚

è¿™ä¸ªæ¢—é€šå¸¸ç”¨æ¥è¡¨è¾¾ä¸€ç§â€œç‹—ç‹—æƒ³åƒäººâ€çš„æç¬‘æƒ…æ™¯ï¼Œè®©äººå¿ä¿Šä¸ç¦ã€‚å› ä¸ºç‹—ç‹—çš„è§†è§‰å’Œå—…è§‰èƒ½åŠ›æœ‰é™ï¼Œå®ƒä»¬æ— æ³•åˆ†è¾¨é£Ÿç‰©çš„æ¥æºï¼Œæ‰€ä»¥å®ƒä»¬ç»å¸¸ä¼šè¯¯ä»¥ä¸ºäººç±»æ˜¯é£Ÿç‰©æ¥æºï¼Œä»è€Œè¡¨ç°å‡ºç±»ä¼¼çš„è¡Œä¸ºã€‚è¿™ä¸ªæ¢—åœ¨ç½‘ç»œç¤¾åŒºä¸­éå¸¸æµè¡Œï¼Œå¸¸è¢«ç”¨æ¥åˆ¶é€ ç¬‘æ–™å’Œå¨±ä¹æ•ˆæœã€‚
```
å‡†å¤‡å¾®è°ƒé…ç½®æ–‡ä»¶
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# xtuner copy-cfg internvl_v2_internlm2_2b_qlora_finetune ./
Copy to ./internvl_v2_internlm2_2b_qlora_finetune_copy.py
```
å¼€å§‹è®­ç»ƒï¼
```bash
export NPROC_PER_MODE=1
xtuner train ./internvl_v2_internlm2_2b_qlora_finetune_copy.py --deepspeed deepspeed_zero1
```

è®­ç»ƒå®Œæˆåè¿è¡Œ
```bash
python xtuner/xtuner/configs/internvl/v1_5/convert_to_official.py ./internvl_v2_internlm2_2b_qlora_finetune_copy.py  work_dir/i
nternvl_qlora_ft/iter_2000.pth ./work_dir/converted_intervl_qlora_config
```
å°†æ¨¡å‹è½¬ä¸ºæ ‡å‡†hfæ¨¡å‹ï¼›
åè¿è¡Œ[è„šæœ¬](./test_qlora.py)
- å°æ’æ›²
ä¸€å¼€å§‹è¿è¡Œæ—¶æŠ¥é”™ï¼š
```bash
python test_qlora.py 
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                                                                        
Traceback (most recent call last):
  File "/root/InternLM-813/L2/InternVL/test_qlora.py", line 4, in <module>
    pipe = pipeline('/root/InternLM-813/L2/InternVL/work_dir/converted_intervl_qlora_config')
  File "/root/.conda/envs/demo/lib/python3.10/site-packages/lmdeploy/api.py", line 89, in pipeline
    return pipeline_class(model_path,
  File "/root/.conda/envs/demo/lib/python3.10/site-packages/lmdeploy/serve/vl_async_engine.py", line 29, in __init__
    self.vl_prompt_template = get_vl_prompt_template(
  File "/root/.conda/envs/demo/lib/python3.10/site-packages/lmdeploy/vl/templates.py", line 308, in get_vl_prompt_template
    assert type(chat_template) != type(BaseModel()), 'failed to match ' \
AssertionError: failed to match chat template, please explicit set chat_template_config
```
æ‰¾ä¸åˆ°Templateï¼Œæ ¹æ®ç¾¤ä½¬çš„å›å¤ï¼Œå¯åœ¨pipelineæŒ‡å®šchat template  

æ•ˆæœï¼š  
![](./test.jpg)
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_qlora.py    
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                                                                        
ä»–ä¸æ˜¯è¢«ç‹—åƒäº†ï¼Œæ˜¯è¢«äººä¸‹äº†æ¯’ï¼Œä½†æ˜¯å‘³é“è¿˜ä¸é”™ã€‚
```
***
### è¿›é˜¶æ•™ç¨‹
æœ¬äººä¸ä¼šè°ƒå‚ï¼Œæ‰€ä»¥é€‰äº†ä¸€ä¸ªä¸ç”¨è°ƒå‚ï¼ˆå¤§æ¦‚ï¼‰çš„Optimizer--> DAdapAdam
é…ç½®æ–‡ä»¶é™„åœ¨[è„šæœ¬](./diy_config)
ä¾ç…§ä¸Šè¿°æµç¨‹è¿›è¡Œè®­ç»ƒåï¼Œè®­ç»ƒlosså¯¹æ¯”å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
![](./Dadap_loss.jpg)
ï¼ˆå› ä¸ºåœ¨ä½¿ç”¨DAdapAdamè®­ç»ƒæ—¶æŠŠbatchsizeå¢å¤§äº†ï¼Œæ‰€ä»¥iterå°ï¼‰
***
**æµ‹è¯•æ•ˆæœ**  

![](./test.jpg)
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_diy_config.py 
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                                                                        
çŒœçŒœå“ªä¸ªå¤¹çš„æ˜¯ç‹—å±
```

![](./test2.png)

```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_qlora.py      
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                                                                        
æˆ‘å˜´ä¸Šçš„è¡¨è¾¾ï¼šè€å­è¢«é›·åŠˆäº†
```
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_diy_config.py 
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                                                                        
æˆ‘æ²¡åƒè¿‡è±†è…ï¼Œä½†æ˜¯æˆ‘åƒè¿‡äº†è›‹ç™½ç²‰ï¼Œæ²¡é”™ï¼Œå°±æ˜¯ä½ äº†ï¼ŒAC Gaiï¼Œè¿™ä¸‹ä½ åƒé†‹äº†æ˜¯ä¸æ˜¯ï¼Ÿ
```

![](./test3.png)
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_qlora.py 
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                                                                        
å·¦ï¼šä½ å¥½ï¼Œæˆ‘å«å·¦
```

```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_diy_config.py 
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                                                                        
ç‹—
```
![](./test4.png)  
```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_qlora.py 
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                                                                        
æ¬¢è¿å…‰ä¸´ï¼
```

```bash
(demo) (base) root@intern-studio-50088800:~/InternLM-813/L2/InternVL# python test_diy_config.py 
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[WARNING] gemm_config.in is not found; using default GEMM algo                                                                                                                        
æˆ‘åšäº†ã€‚
```







